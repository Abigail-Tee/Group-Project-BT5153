{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import all the dependencies\n",
    "import pandas as pd\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = pd.read_csv('books_cleaned_v4.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 50000\n",
      "Test size: 10000\n"
     ]
    }
   ],
   "source": [
    "#Train\n",
    "train = books[:50000]\n",
    "print('Train size:', len(train))\n",
    "#train.to_csv('doc2vec_v1/books_train.csv',index = False)\n",
    "\n",
    "#Test\n",
    "test = books[50000:60000]\n",
    "print('Test size:', len(test))\n",
    "#test.to_csv('doc2vec_v1/books_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'[^a-zA-Z]',' ',text) #only keep letters\n",
    "    return text\n",
    "    \n",
    "books['description'] = books['description'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_description = train['description']\n",
    "test_description = test['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        major motion picture starring amanda stenberg ...\n",
       "1        deeply moving original dealing material encoun...\n",
       "2        acclaimed eagerly anticipated fourth thriller ...\n",
       "3        epicene widely studied johnson play brilliantl...\n",
       "4        little critter class going critterville museum...\n",
       "                               ...                        \n",
       "49995    change die option available planet jeep centur...\n",
       "49996    captain mackenzie calhoun faced incredible odd...\n",
       "49997    world divided flier non flier far able fly sac...\n",
       "49998    doubt ll bigger insect gabby nichols putting s...\n",
       "49999    mysterious murder dystopian future lead novice...\n",
       "Name: description, Length: 50000, dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000    conversation shift debate existence global war...\n",
       "50001    born agrarian ghetto dickens southern outskirt...\n",
       "50002    length novel novella collected time volume sev...\n",
       "50003    elegance wealth privilege politics extravaganc...\n",
       "50004    kit kenyon rate hostage negotiator noah lamber...\n",
       "                               ...                        \n",
       "59995    year old winnie willis way horse gentle wildes...\n",
       "59996    winner      obie playwriting critic pick invas...\n",
       "59997    installment dci daley series packed accurate p...\n",
       "59998    walk tombstone star liam neeson unlicensed pri...\n",
       "59999    sensational thriller richard amp judy lie save...\n",
       "Name: description, Length: 10000, dtype: object"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tagged_data = [TaggedDocument(words=word_tokenize(d), tags=[str(i)]) for i, d in enumerate(train_description)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = 2000\n",
    "epochs = 5\n",
    "\n",
    "model = Doc2Vec(size=features,\n",
    "                min_count=1,\n",
    "                dm =1, #distributed memory, preserves word order \n",
    "                epochs = epochs) \n",
    "#Build vocab\n",
    "model.build_vocab(tagged_data)\n",
    "\n",
    "#Train model \n",
    "print('Training Model...')\n",
    "%time model.train(tagged_data, total_examples=model.corpus_count, epochs=model.epochs)\n",
    "\n",
    "#model.save(\"doc2vec_v1/d2v_v1.model\")\n",
    "print(\"Model Saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load model\n",
    "#model= Doc2Vec.load(\"doc2vec_v1/d2v_v1.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing for: 10000 out of 10000 books\n",
      "Current run time: 32.2 minutes\n"
     ]
    }
   ],
   "source": [
    "#document vector for TEST set\n",
    "document_vector_test = pd.DataFrame()\n",
    "start = timeit.default_timer()\n",
    "for x in range(50000,60000): \n",
    "    clear_output(wait=True)\n",
    "    description = word_tokenize(test_description[x])\n",
    "    vector = model.infer_vector(description)\n",
    "    vector = vector.reshape(1,2000).tolist()\n",
    "    document_vector_test = document_vector_test.append(vector)\n",
    "    \n",
    "    stop = timeit.default_timer()\n",
    "    print('Computing for: {} out of {} books'.format(len(document_vector_test),len(test_description)))\n",
    "    print('Current run time:', np.round((stop-start)/60, 2), \"minutes\")\n",
    "\n",
    "#document_vector_test.to_csv('doc2vec_v1/vector_test.csv',index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01326105, -0.00677363, -0.00065993, ...,  0.00704421,\n",
       "         0.00545914,  0.00709073],\n",
       "       [-0.01312576, -0.00297036,  0.00069041, ..., -0.0133282 ,\n",
       "        -0.01843835, -0.01881793],\n",
       "       [ 0.0069616 ,  0.00108923, -0.00911423, ...,  0.00695539,\n",
       "         0.01784323,  0.01078568],\n",
       "       ...,\n",
       "       [-0.02609154,  0.00399439,  0.00015313, ..., -0.00907762,\n",
       "        -0.0138525 , -0.01453141],\n",
       "       [-0.01182391,  0.00527959,  0.00335627, ...,  0.00764601,\n",
       "         0.00775823,  0.00235519],\n",
       "       [-0.01195882, -0.01418764, -0.01553512, ..., -0.01371097,\n",
       "         0.0035904 , -0.00606263]], dtype=float32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## doc_vectors\n",
    "doc_vectors = np.load('doc2vec_v1/d2v_v1.model.docvecs.vectors_docs.npy')\n",
    "doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_doc_vectors = pd.DataFrame(doc_vectors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1990</th>\n",
       "      <th>1991</th>\n",
       "      <th>1992</th>\n",
       "      <th>1993</th>\n",
       "      <th>1994</th>\n",
       "      <th>1995</th>\n",
       "      <th>1996</th>\n",
       "      <th>1997</th>\n",
       "      <th>1998</th>\n",
       "      <th>1999</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.013261</td>\n",
       "      <td>-0.006774</td>\n",
       "      <td>-0.000660</td>\n",
       "      <td>-0.000293</td>\n",
       "      <td>0.009832</td>\n",
       "      <td>0.010535</td>\n",
       "      <td>0.012721</td>\n",
       "      <td>-0.021488</td>\n",
       "      <td>0.020089</td>\n",
       "      <td>-0.007288</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000458</td>\n",
       "      <td>-0.010699</td>\n",
       "      <td>-0.011727</td>\n",
       "      <td>-0.002300</td>\n",
       "      <td>-0.000770</td>\n",
       "      <td>-0.017063</td>\n",
       "      <td>-0.007267</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>0.005459</td>\n",
       "      <td>0.007091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.013126</td>\n",
       "      <td>-0.002970</td>\n",
       "      <td>0.000690</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.025898</td>\n",
       "      <td>0.012997</td>\n",
       "      <td>-0.005661</td>\n",
       "      <td>-0.018428</td>\n",
       "      <td>0.002324</td>\n",
       "      <td>-0.004618</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>-0.002209</td>\n",
       "      <td>0.008576</td>\n",
       "      <td>0.007704</td>\n",
       "      <td>-0.008213</td>\n",
       "      <td>0.007392</td>\n",
       "      <td>-0.008348</td>\n",
       "      <td>-0.013328</td>\n",
       "      <td>-0.018438</td>\n",
       "      <td>-0.018818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006962</td>\n",
       "      <td>0.001089</td>\n",
       "      <td>-0.009114</td>\n",
       "      <td>-0.016885</td>\n",
       "      <td>0.010773</td>\n",
       "      <td>-0.002402</td>\n",
       "      <td>-0.005502</td>\n",
       "      <td>-0.002807</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>-0.003398</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000081</td>\n",
       "      <td>-0.004995</td>\n",
       "      <td>-0.011408</td>\n",
       "      <td>-0.018035</td>\n",
       "      <td>-0.018796</td>\n",
       "      <td>-0.023806</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.006955</td>\n",
       "      <td>0.017843</td>\n",
       "      <td>0.010786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025949</td>\n",
       "      <td>0.011242</td>\n",
       "      <td>0.003029</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>0.057221</td>\n",
       "      <td>0.019470</td>\n",
       "      <td>-0.006770</td>\n",
       "      <td>-0.018691</td>\n",
       "      <td>0.012505</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.020105</td>\n",
       "      <td>-0.015469</td>\n",
       "      <td>-0.004803</td>\n",
       "      <td>0.003606</td>\n",
       "      <td>-0.011103</td>\n",
       "      <td>-0.030019</td>\n",
       "      <td>-0.017571</td>\n",
       "      <td>0.013098</td>\n",
       "      <td>-0.016627</td>\n",
       "      <td>-0.012313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.006467</td>\n",
       "      <td>-0.003168</td>\n",
       "      <td>0.008910</td>\n",
       "      <td>0.001557</td>\n",
       "      <td>-0.007594</td>\n",
       "      <td>0.001969</td>\n",
       "      <td>0.000561</td>\n",
       "      <td>0.006724</td>\n",
       "      <td>0.002906</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002134</td>\n",
       "      <td>0.004945</td>\n",
       "      <td>0.002511</td>\n",
       "      <td>-0.001814</td>\n",
       "      <td>0.005236</td>\n",
       "      <td>0.002875</td>\n",
       "      <td>0.005892</td>\n",
       "      <td>-0.001138</td>\n",
       "      <td>-0.005302</td>\n",
       "      <td>0.007656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49995</th>\n",
       "      <td>-0.008076</td>\n",
       "      <td>-0.003420</td>\n",
       "      <td>-0.018366</td>\n",
       "      <td>0.008141</td>\n",
       "      <td>-0.011269</td>\n",
       "      <td>-0.003109</td>\n",
       "      <td>-0.006503</td>\n",
       "      <td>-0.028337</td>\n",
       "      <td>0.003290</td>\n",
       "      <td>-0.009394</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002384</td>\n",
       "      <td>-0.001133</td>\n",
       "      <td>-0.021003</td>\n",
       "      <td>-0.003154</td>\n",
       "      <td>-0.015112</td>\n",
       "      <td>0.006887</td>\n",
       "      <td>-0.027732</td>\n",
       "      <td>0.005829</td>\n",
       "      <td>-0.007524</td>\n",
       "      <td>-0.008869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49996</th>\n",
       "      <td>-0.009236</td>\n",
       "      <td>0.007370</td>\n",
       "      <td>-0.010313</td>\n",
       "      <td>-0.004612</td>\n",
       "      <td>-0.006230</td>\n",
       "      <td>0.006149</td>\n",
       "      <td>0.001094</td>\n",
       "      <td>-0.006059</td>\n",
       "      <td>0.011299</td>\n",
       "      <td>-0.024790</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000328</td>\n",
       "      <td>-0.002762</td>\n",
       "      <td>0.000538</td>\n",
       "      <td>0.000148</td>\n",
       "      <td>-0.010283</td>\n",
       "      <td>0.000737</td>\n",
       "      <td>0.001922</td>\n",
       "      <td>0.010913</td>\n",
       "      <td>-0.004503</td>\n",
       "      <td>-0.011972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49997</th>\n",
       "      <td>-0.026092</td>\n",
       "      <td>0.003994</td>\n",
       "      <td>0.000153</td>\n",
       "      <td>-0.000263</td>\n",
       "      <td>0.017731</td>\n",
       "      <td>0.022106</td>\n",
       "      <td>-0.006670</td>\n",
       "      <td>-0.028385</td>\n",
       "      <td>0.008884</td>\n",
       "      <td>-0.021834</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003421</td>\n",
       "      <td>-0.012852</td>\n",
       "      <td>-0.003111</td>\n",
       "      <td>0.007272</td>\n",
       "      <td>-0.010175</td>\n",
       "      <td>-0.000518</td>\n",
       "      <td>-0.026980</td>\n",
       "      <td>-0.009078</td>\n",
       "      <td>-0.013853</td>\n",
       "      <td>-0.014531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49998</th>\n",
       "      <td>-0.011824</td>\n",
       "      <td>0.005280</td>\n",
       "      <td>0.003356</td>\n",
       "      <td>-0.004782</td>\n",
       "      <td>0.008378</td>\n",
       "      <td>0.004838</td>\n",
       "      <td>-0.010237</td>\n",
       "      <td>-0.014871</td>\n",
       "      <td>0.015584</td>\n",
       "      <td>-0.009218</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.007070</td>\n",
       "      <td>-0.006861</td>\n",
       "      <td>0.000704</td>\n",
       "      <td>-0.010008</td>\n",
       "      <td>-0.006082</td>\n",
       "      <td>-0.009305</td>\n",
       "      <td>-0.011328</td>\n",
       "      <td>0.007646</td>\n",
       "      <td>0.007758</td>\n",
       "      <td>0.002355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49999</th>\n",
       "      <td>-0.011959</td>\n",
       "      <td>-0.014188</td>\n",
       "      <td>-0.015535</td>\n",
       "      <td>0.007709</td>\n",
       "      <td>0.031412</td>\n",
       "      <td>0.012513</td>\n",
       "      <td>-0.009311</td>\n",
       "      <td>-0.039771</td>\n",
       "      <td>0.001757</td>\n",
       "      <td>-0.006441</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008401</td>\n",
       "      <td>0.008502</td>\n",
       "      <td>0.017968</td>\n",
       "      <td>-0.007286</td>\n",
       "      <td>-0.029940</td>\n",
       "      <td>0.021049</td>\n",
       "      <td>-0.011040</td>\n",
       "      <td>-0.013711</td>\n",
       "      <td>0.003590</td>\n",
       "      <td>-0.006063</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>50000 rows Ã— 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0         1         2         3         4         5         6     \\\n",
       "0     -0.013261 -0.006774 -0.000660 -0.000293  0.009832  0.010535  0.012721   \n",
       "1     -0.013126 -0.002970  0.000690  0.012485  0.025898  0.012997 -0.005661   \n",
       "2      0.006962  0.001089 -0.009114 -0.016885  0.010773 -0.002402 -0.005502   \n",
       "3     -0.025949  0.011242  0.003029  0.011299  0.057221  0.019470 -0.006770   \n",
       "4      0.006467 -0.003168  0.008910  0.001557 -0.007594  0.001969  0.000561   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "49995 -0.008076 -0.003420 -0.018366  0.008141 -0.011269 -0.003109 -0.006503   \n",
       "49996 -0.009236  0.007370 -0.010313 -0.004612 -0.006230  0.006149  0.001094   \n",
       "49997 -0.026092  0.003994  0.000153 -0.000263  0.017731  0.022106 -0.006670   \n",
       "49998 -0.011824  0.005280  0.003356 -0.004782  0.008378  0.004838 -0.010237   \n",
       "49999 -0.011959 -0.014188 -0.015535  0.007709  0.031412  0.012513 -0.009311   \n",
       "\n",
       "           7         8         9     ...      1990      1991      1992  \\\n",
       "0     -0.021488  0.020089 -0.007288  ...  0.000458 -0.010699 -0.011727   \n",
       "1     -0.018428  0.002324 -0.004618  ...  0.001467 -0.002209  0.008576   \n",
       "2     -0.002807 -0.006670 -0.003398  ... -0.000081 -0.004995 -0.011408   \n",
       "3     -0.018691  0.012505  0.003356  ... -0.020105 -0.015469 -0.004803   \n",
       "4      0.006724  0.002906 -0.001929  ... -0.002134  0.004945  0.002511   \n",
       "...         ...       ...       ...  ...       ...       ...       ...   \n",
       "49995 -0.028337  0.003290 -0.009394  ...  0.002384 -0.001133 -0.021003   \n",
       "49996 -0.006059  0.011299 -0.024790  ... -0.000328 -0.002762  0.000538   \n",
       "49997 -0.028385  0.008884 -0.021834  ...  0.003421 -0.012852 -0.003111   \n",
       "49998 -0.014871  0.015584 -0.009218  ... -0.007070 -0.006861  0.000704   \n",
       "49999 -0.039771  0.001757 -0.006441  ... -0.008401  0.008502  0.017968   \n",
       "\n",
       "           1993      1994      1995      1996      1997      1998      1999  \n",
       "0     -0.002300 -0.000770 -0.017063 -0.007267  0.007044  0.005459  0.007091  \n",
       "1      0.007704 -0.008213  0.007392 -0.008348 -0.013328 -0.018438 -0.018818  \n",
       "2     -0.018035 -0.018796 -0.023806  0.002141  0.006955  0.017843  0.010786  \n",
       "3      0.003606 -0.011103 -0.030019 -0.017571  0.013098 -0.016627 -0.012313  \n",
       "4     -0.001814  0.005236  0.002875  0.005892 -0.001138 -0.005302  0.007656  \n",
       "...         ...       ...       ...       ...       ...       ...       ...  \n",
       "49995 -0.003154 -0.015112  0.006887 -0.027732  0.005829 -0.007524 -0.008869  \n",
       "49996  0.000148 -0.010283  0.000737  0.001922  0.010913 -0.004503 -0.011972  \n",
       "49997  0.007272 -0.010175 -0.000518 -0.026980 -0.009078 -0.013853 -0.014531  \n",
       "49998 -0.010008 -0.006082 -0.009305 -0.011328  0.007646  0.007758  0.002355  \n",
       "49999 -0.007286 -0.029940  0.021049 -0.011040 -0.013711  0.003590 -0.006063  \n",
       "\n",
       "[50000 rows x 2000 columns]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_doc_vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_doc_vectors.to_csv('doc2vec_v1/vector_train.csv',index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find similar documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similar_documents(book_index):\n",
    "    similar_doc = model.docvecs.most_similar([book_index])\n",
    "    print('Book Searched')\n",
    "    print(train.loc[book_index,'title'])\n",
    "    print(train.loc[book_index,'description_original'])\n",
    "    print(train.loc[book_index,'genres'])\n",
    "    \n",
    "    print('\\nMost Similar Books:')\n",
    "    \n",
    "    print('\\n----------Rank 1------------')\n",
    "    rank = int(similar_doc[0][0])\n",
    "    print(rank)\n",
    "    print(train.loc[rank,'title'])\n",
    "    print(train.loc[rank,'description_original'])\n",
    "    print(train.loc[rank,'genres'])\n",
    "    \n",
    "    print('\\n----------Rank 2------------')\n",
    "    rank = int(similar_doc[1][0])\n",
    "    print(rank)\n",
    "    print(train.loc[rank,'title'])\n",
    "    print(train.loc[rank,'description_original'])\n",
    "    print(train.loc[rank,'genres'])\n",
    "    \n",
    "    print('\\n----------Rank 3------------')\n",
    "    rank = int(similar_doc[2][0])\n",
    "    print(rank)\n",
    "    print(train.loc[rank,'title'])\n",
    "    print(train.loc[rank,'description_original'])\n",
    "    print(train.loc[rank,'genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # thriller \n",
    "# similar_documents(108)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # romance \n",
    "# similar_documents(31000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
