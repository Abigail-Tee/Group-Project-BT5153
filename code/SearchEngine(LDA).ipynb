{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from sklearn.decomposition import LatentDirichletAllocation, TruncatedSVD\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import timeit\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import cleaned dataset fiction books only \n",
    "books = pd.read_csv('books_cleaned_v4.csv')\n",
    "#Import cleaned reviews\n",
    "reviews = pd.read_csv('reviews_cleaned_short.csv')\n",
    "#Import doc-topic model\n",
    "df_document_topic = pd.read_csv('LDA50kfictionnewclean/df_document_topic.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "books.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books = books[:50000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "books.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Document Term Matrix \n",
    "df_document_topic = df_document_topic.drop(columns = ['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_document_topic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load vectorizer \n",
    "vectorizer = pickle.load(open(\"LDA50kfictionnewclean/vectorizer.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load trained LDA model \n",
    "lda_model = pickle.load(open(\"LDA50kfictionnewclean/lda_model.pk\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scale Number of Ratings and Average Rating for books "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "books['rating_count_scaled'] = scaler.fit_transform(books[['rating-count']])\n",
    "books['avg_rating_scaled'] = scaler.fit_transform(books[['rating-avg']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search - Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "add_sw = ['new','york','times','bestseller','bestselling','author','prize','putlizer']\n",
    "sw = STOPWORDS.union(set(add_sw))\n",
    "eng_words = set(nltk.corpus.words.words())\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub('<.*?>', ' ', text) #remove tags \n",
    "    text = re.sub(r'[^a-zA-Z]',' ',text) #remove anything that is not an alphabet \n",
    "    #Remove stop words\n",
    "    text = re.split(r'[^\\w]+',text) \n",
    "    text_filtered = [w for w in text if not w in sw]\n",
    "    #Lemmatize \n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    text_lemmatized = [lemmatizer.lemmatize(w) for w in text_filtered]\n",
    "    #remove short words\n",
    "    text_filtered = [w for w in text_lemmatized if len(w)>1]\n",
    "    text_filtered = ' '.join(text_filtered).strip()\n",
    "    return text_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import heapq\n",
    "num_topics = 2000\n",
    "def search_books(text, number_books_recommend, popular = 1):\n",
    "    start = timeit.default_timer()\n",
    "    #clean new text input \n",
    "    text = clean_text(text)\n",
    "    #vectorize clean text\n",
    "    text_vectorized = vectorizer.transform([text])\n",
    "    topic_probability = lda_model.transform(text_vectorized)\n",
    "    \n",
    "    #compute similarity\n",
    "    similarity_array = cosine_similarity(df_document_topic, topic_probability, dense_output=True)\n",
    "    #most_similar_books = heapq.nlargest(number_books_recommend, range(len(similarity_array)), similarity_array.__getitem__)\n",
    "    book_copy = books.copy()\n",
    "    book_copy['similarity'] = similarity_array\n",
    "    \n",
    "    #sort \n",
    "    book_copy = book_copy.sort_values(by = 'similarity', ascending = False)\n",
    "    \n",
    "    #popular books - filter books that have more than 100000 ratings \n",
    "    if popular != 0: \n",
    "        book_copy = book_copy[book_copy['rating-count']>100000]\n",
    "\n",
    "    #print recommended books\n",
    "    most_similar_books = book_copy.index[:number_books_recommend]\n",
    "\n",
    "    for book_index in most_similar_books:\n",
    "        print(book_copy.loc[book_index,'title'])\n",
    "        print(book_copy.loc[book_index,'description_original'])\n",
    "        print('ISBN:',book_copy.loc[book_index,'isbn13'])\n",
    "        print('Rating:',book_copy.loc[book_index,'rating-avg'])\n",
    "        print('Number of ratings:',book_copy.loc[book_index,'rating-count'])\n",
    "        print('Cosine Similarity:', book_copy.loc[book_index,'similarity'])\n",
    "        print('Genre:', book_copy.loc[book_index,'genres'])\n",
    "        #print('Rank:', book_copy.loc[book_index,'rank'])\n",
    "        print('\\n')\n",
    "        \n",
    "    stop = timeit.default_timer()\n",
    "    print('Run time:', np.round((stop-start)/60, 2), \"minutes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fantasy \n",
    "search_books('wizarding magic',10,popular = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# thriller \n",
    "search_books('serial killer murder detective',10, popular = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#science fiction - dystopian \n",
    "search_books('dystopian end of world',10, popular = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#books that have reviews\n",
    "books_reviews = books[books['isbn13'].isin(reviews['isbn13'])]\n",
    "print('Number of books with reviews:', len(books_reviews))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_books_score(text, number_books_recommend):\n",
    "    predicted_isbn = []\n",
    "    #clean new text input \n",
    "    text = clean_text(text)\n",
    "    #vectorize clean text\n",
    "    text_vectorized = vectorizer.transform([text])\n",
    "    topic_probability = lda_model.transform(text_vectorized)\n",
    "    \n",
    "    #compute similarity\n",
    "    similarity_array = cosine_similarity(df_document_topic, topic_probability, dense_output=True)\n",
    "    #most_similar_books = heapq.nlargest(number_books_recommend, range(len(similarity_array)), similarity_array.__getitem__)\n",
    "    book_copy = books.copy()\n",
    "    book_copy['similarity'] = similarity_array\n",
    "    \n",
    "    #sort \n",
    "    book_copy = book_copy.sort_values(by = 'similarity', ascending = False)\n",
    "\n",
    "    #print recommended books\n",
    "    most_similar_books = book_copy.index[:number_books_recommend]\n",
    "    \n",
    "    for book_index in most_similar_books:\n",
    "        isbn = book_copy.loc[book_index,'isbn13']\n",
    "        predicted_isbn.append(isbn)\n",
    "    \n",
    "    return predicted_isbn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_df(df,number_books_recommend):\n",
    "    start = timeit.default_timer()\n",
    "    for x in range(0,len(df)):\n",
    "        clear_output(wait=True)\n",
    "\n",
    "        isbn = df.loc[x,'isbn13']\n",
    "        text = df.loc[x,'review']\n",
    "        predicted_isbn = search_books_score(text,number_books_recommend)\n",
    "        df.at[x,'predicted_isbn'] = predicted_isbn\n",
    "\n",
    "        stop = timeit.default_timer()\n",
    "\n",
    "        print('Current progress: {} out of {} rows'.format(x+1,len(df)))\n",
    "        print('Current run time:', np.round((stop-start)/60, 2), \"minutes\")\n",
    "    \n",
    "    print('Computing Score') \n",
    "    \n",
    "    df['intersection'] = df.apply(lambda x: x['isbn13'] in x['predicted_isbn'] ,axis = 1)\n",
    "    df['score'] = np.where(df['intersection'] == False,0,1)\n",
    "    \n",
    "    accuracy = df['score'].sum() / len(df) * 100\n",
    "    print('Accuracy: {} %'.format(accuracy))\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_books(df,correct = 1): \n",
    "    if correct == 1:   \n",
    "        filtered_index = df[df['score'] == 1].index\n",
    "        \n",
    "    #for 3 correctly predicted reviews\n",
    "        for x in range(0,3):   \n",
    "            index_1 = filtered_index[x]\n",
    "            review_isbn = df.loc[index_1,'isbn13']\n",
    "            review = df.loc[index_1,'review']\n",
    "            description = books[books['isbn13'] == review_isbn]['description_original'].values\n",
    "            title = books[books['isbn13'] == review_isbn]['title'].values\n",
    "            \n",
    "            print('\\n-----Review-----')\n",
    "            print('Book title for review:', title)\n",
    "            print('Review:')\n",
    "            print(review)\n",
    "\n",
    "            print('\\n-----Target book------')\n",
    "            print('Title:',title)\n",
    "            print(description)\n",
    "\n",
    "    else:\n",
    "        filtered_index = df[df['score'] == 0].index\n",
    "    \n",
    "    #for 3 wrongly predicted reviews\n",
    "        for x in range(0,3):    \n",
    "            index_1 = filtered_index[x]\n",
    "            review_isbn = df.loc[index_1,'isbn13']\n",
    "            review = df.loc[index_1,'review']\n",
    "\n",
    "            description = books[books['isbn13'] == review_isbn]['description_original'].values\n",
    "            title = books[books['isbn13'] == review_isbn]['title'].values\n",
    "            \n",
    "            print('\\n-----Review-----')\n",
    "            print('Book title for review:', title)\n",
    "            print('Review:')\n",
    "            print(review)\n",
    "\n",
    "            print('\\n-----Target Book------')\n",
    "            print('Title:',title)\n",
    "            print(description)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing - Fantasy Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy = books_reviews[books_reviews['genres'].str.contains('fantasy',na = False)]\n",
    "print('Number of fantasy books with at least 1 review:', len(fantasy))\n",
    "\n",
    "fantasy_reviews = reviews[reviews['isbn13'].isin(fantasy['isbn13'])]\n",
    "print('Number of reviews for fantasy books:', len(fantasy_reviews))\n",
    "fantasy_reviews_sample = fantasy_reviews.sample(200, random_state = 20).reset_index(drop = True)\n",
    "fantasy_reviews_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fantasy_reviews_sample = fantasy_reviews_sample[['isbn13','review']]\n",
    "fantasy_reviews_sample['predicted_isbn'] = None\n",
    "fantasy_reviews_sample['predicted_isbn'] = fantasy_reviews_sample['predicted_isbn'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_fantasy = test_df(fantasy_reviews_sample,10)\n",
    "test_fantasy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_books(test_fantasy,correct = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_books(test_fantasy,correct = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing - Thriller Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thriller = books_reviews[books_reviews['genres'].str.contains('thriller',na = False)]\n",
    "print('Number of thriller books with at least 1 review:', len(thriller))\n",
    "\n",
    "thriller_reviews = reviews[reviews['isbn13'].isin(thriller['isbn13'])]\n",
    "print('Number of reviews for thriller:', len(thriller_reviews))\n",
    "thriller_reviews_sample = thriller_reviews.sample(200, random_state = 20).reset_index(drop = True)\n",
    "thriller_reviews_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thriller_reviews_sample = thriller_reviews_sample[['isbn13','review']]\n",
    "thriller_reviews_sample['predicted_isbn'] = None\n",
    "thriller_reviews_sample['predicted_isbn'] = thriller_reviews_sample['predicted_isbn'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_thriller = test_df(thriller_reviews_sample,10)\n",
    "test_thriller "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_books(test_thriller ,correct = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "show_books(test_thriller ,correct = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing - Science Fiction Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "science_fiction = books_reviews[books_reviews['genres'].str.contains('science-fiction',na = False)]\n",
    "print('Number of science fiction books with at least 1 review:', len(science_fiction))\n",
    "\n",
    "sf_reviews = reviews[reviews['isbn13'].isin(science_fiction['isbn13'])]\n",
    "print('Number of reviews for science fiction books:', len(sf_reviews))\n",
    "sf_reviews_sample = sf_reviews.sample(200, random_state = 20).reset_index(drop = True)\n",
    "sf_reviews_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sf_reviews_sample = sf_reviews_sample[['isbn13','review']]\n",
    "sf_reviews_sample['predicted_isbn'] = None\n",
    "sf_reviews_sample['predicted_isbn'] = sf_reviews_sample['predicted_isbn'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_sf = test_df(sf_reviews_sample,10)\n",
    "test_sf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_books(test_sf ,correct = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_books(test_sf ,correct = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing - Romance Books"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romance = books_reviews[books_reviews['genres'].str.contains('romance',na = False)]\n",
    "print('Number of romance books with at least 1 review:', len(romance))\n",
    "\n",
    "romance_reviews = reviews[reviews['isbn13'].isin(romance['isbn13'])]\n",
    "print('Number of reviews for romance books:', len(romance_reviews))\n",
    "romance_reviews_sample = romance_reviews.sample(200, random_state = 20).reset_index(drop = True)\n",
    "romance_reviews_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "romance_reviews_sample = romance_reviews_sample[['isbn13','review']]\n",
    "romance_reviews_sample['predicted_isbn'] = None\n",
    "romance_reviews_sample['predicted_isbn'] = romance_reviews_sample['predicted_isbn'].astype(object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_romance = test_df(romance_reviews_sample,10)\n",
    "test_romance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_books(test_romance ,correct = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_books(test_romance ,correct = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
